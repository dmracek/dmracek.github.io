{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome Thank you for visiting! I am an award-winning thought leader and trusted advisor\u2014building bold and trusted talent solutions for many leading companies. Derek L Mracek, PhD","title":"Welcome"},{"location":"#welcome","text":"Thank you for visiting! I am an award-winning thought leader and trusted advisor\u2014building bold and trusted talent solutions for many leading companies. Derek L Mracek, PhD","title":"Welcome"},{"location":"background/background/","text":"Vision Artificial intelligence is eating the world Yet, we need to blend domain expertise {w/ } to build world class solutions { } Check out the blog \u2013 Explorations + Code \u2013 where I look to thread this needle For more information on how I can help you out \u2013 feel free to connect \ud83e\udd1d\ud83c\udffc Derek L Mracek, PhD Resume Awards Thought Leadership Focus Strategy Domain expertise People Science Measurement & Assessment Diversity, Fairness & Legal Defensibility People Analytics Natural Language Processing (NLP) Artificial Intelligence & Deep Learning Technology & Software Development Consulting Professional Fun C Suite Experience Connect \u2013 Email \u2013 Twitter \u2013 LinkedIn","title":"Background"},{"location":"background/background/#vision","text":"Artificial intelligence is eating the world Yet, we need to blend domain expertise {w/ } to build world class solutions { } Check out the blog \u2013 Explorations + Code \u2013 where I look to thread this needle For more information on how I can help you out \u2013 feel free to connect \ud83e\udd1d\ud83c\udffc Derek L Mracek, PhD Resume Awards Thought Leadership","title":"Vision"},{"location":"background/background/#focus","text":"","title":"Focus"},{"location":"background/background/#strategy","text":"Domain expertise People Science Measurement & Assessment Diversity, Fairness & Legal Defensibility People Analytics Natural Language Processing (NLP) Artificial Intelligence & Deep Learning Technology & Software Development Consulting Professional Fun C Suite Experience","title":"Strategy"},{"location":"background/background/#connect","text":"\u2013 Email \u2013 Twitter \u2013 LinkedIn","title":"Connect"},{"location":"explorations_code_nbs/exploration_background/","text":"Explorations + Code In this space I explore new ML technology and add a people science spin to it Code for the site including the Explorations + Code blog can be found on Links to the machine-learning code can also be found at the top of each post For example Support This Site Recent Post(s) Click the below for the full write up. \ud83e\udde0\ud83d\ude80 Scaling Expertise Feb 25, 2021 \ud83d\udcd6 ~15 min read TLDR: Snorkel is a fitting framework that promotes SMEs ability to impart their wisdom to scale . Specifically, we Programmed functions in Python that mapped onto our SME ground truth gold labels Zero-shot predictions for the 35 factors/facets of the Big 5 personality taxonomy TextBlob sentiment Pattern-based heuristics (i.e., keywords) Created a generative model based on accuracies and correlations of our labeling functions Programmatically labeled all of our unlabeled responses Trained a machine learning model on all (previously unlabeled) data Strategy works with guidelines and ethical considerations for assessment center operations \ud83c\udf99\ufe0f GPT-2 Interview Response Nov 12, 2020 \ud83d\udcd6 < 5 min read It's been a turvy topsy year. I'm looking for someone or something to help lighten my workload. Let's interview the GPT-2 artificial intelligence language model \u2013 the gpt-2-simple package \u2013 for the job TLDR: After learning more about GPT-2 artificial intelligence's working style I am feeling optimistic. Specifically, we Interviewed GPT-2 and asked it to describe it's work style Evaluated the GPT-2 interview response in terms of the O*NET work styles (WS) Top WS: Concern for Others , Attention to Detail , and Social Orientation Bottom WS: Self Control , Stress Tolerance , and Achievement Effort Used zero-shot classification to evaluate the responses GPT-2 response appears in keeping with the following occupations Sociologist Anthropologist \ud83c\udff7\ufe0f Zero-shot Classify Big 5 Personality Oct 27, 2020 \ud83d\udcd6 15 min read Zero-shot learning (ZSL) \u2013 from the Transformers package \u2013 is an exciting approach to classify text responses in terms of a label or set of labels not explicitly trained by a model. TLDR: zero-shot looks like an excellent tool for lower-stakes measurement, but for higher-stakes settings such as evaluating someone for a job we need further evidence . Specifically, we Classified scenario based text responses in terms of the Big 5 personality traits Psychometric validity evidence of ZSL was pretty encouraging Face validity \u2013 ZSL scores passed the eyeball test Convergent validity \u2013 ZSL scores were positively related to self-report scores of corresponding traits ZSL was a bit overzealous compared to expert gold standards ZSL did a nice job of classifying agreeable responses as agreeable ZSL struggled to classify only relevant responses as agreeable ZSL maintained an inter-rater agreement/reliability approximately 50% to goal Support This Site","title":"Explorations + Code"},{"location":"explorations_code_nbs/exploration_background/#explorations--code","text":"In this space I explore new ML technology and add a people science spin to it Code for the site including the Explorations + Code blog can be found on Links to the machine-learning code can also be found at the top of each post For example Support This Site","title":"Explorations + Code"},{"location":"explorations_code_nbs/exploration_background/#recent-posts","text":"Click the below for the full write up.","title":"Recent Post(s)"},{"location":"explorations_code_nbs/exploration_background/#-scaling-expertise","text":"Feb 25, 2021 \ud83d\udcd6 ~15 min read TLDR: Snorkel is a fitting framework that promotes SMEs ability to impart their wisdom to scale . Specifically, we Programmed functions in Python that mapped onto our SME ground truth gold labels Zero-shot predictions for the 35 factors/facets of the Big 5 personality taxonomy TextBlob sentiment Pattern-based heuristics (i.e., keywords) Created a generative model based on accuracies and correlations of our labeling functions Programmatically labeled all of our unlabeled responses Trained a machine learning model on all (previously unlabeled) data Strategy works with guidelines and ethical considerations for assessment center operations","title":"\ud83e\udde0\ud83d\ude80 Scaling Expertise"},{"location":"explorations_code_nbs/exploration_background/#-gpt-2-interview-response","text":"Nov 12, 2020 \ud83d\udcd6 < 5 min read It's been a turvy topsy year. I'm looking for someone or something to help lighten my workload. Let's interview the GPT-2 artificial intelligence language model \u2013 the gpt-2-simple package \u2013 for the job TLDR: After learning more about GPT-2 artificial intelligence's working style I am feeling optimistic. Specifically, we Interviewed GPT-2 and asked it to describe it's work style Evaluated the GPT-2 interview response in terms of the O*NET work styles (WS) Top WS: Concern for Others , Attention to Detail , and Social Orientation Bottom WS: Self Control , Stress Tolerance , and Achievement Effort Used zero-shot classification to evaluate the responses GPT-2 response appears in keeping with the following occupations Sociologist Anthropologist","title":"\ud83c\udf99\ufe0f GPT-2 Interview Response"},{"location":"explorations_code_nbs/exploration_background/#-zero-shot-classify-big-5-personality","text":"Oct 27, 2020 \ud83d\udcd6 15 min read Zero-shot learning (ZSL) \u2013 from the Transformers package \u2013 is an exciting approach to classify text responses in terms of a label or set of labels not explicitly trained by a model. TLDR: zero-shot looks like an excellent tool for lower-stakes measurement, but for higher-stakes settings such as evaluating someone for a job we need further evidence . Specifically, we Classified scenario based text responses in terms of the Big 5 personality traits Psychometric validity evidence of ZSL was pretty encouraging Face validity \u2013 ZSL scores passed the eyeball test Convergent validity \u2013 ZSL scores were positively related to self-report scores of corresponding traits ZSL was a bit overzealous compared to expert gold standards ZSL did a nice job of classifying agreeable responses as agreeable ZSL struggled to classify only relevant responses as agreeable ZSL maintained an inter-rater agreement/reliability approximately 50% to goal Support This Site","title":"\ud83c\udff7\ufe0f Zero-shot Classify Big 5 Personality"},{"location":"explorations_code_nbs/exploration_gpt2_ws/","text":"\ud83c\udf99\ufe0f GPT-2 Interview Response Nov 12, 2020 \ud83d\udcd6 < 5 min read Support This Site Adios Human Co-workers (?) It's been a turvy topsy year. I'm looking for someone or something to help lighten my workload. Let's interview the GPT-2 artificial intelligence language model \u2013 the gpt-2-simple package \u2013 for the job Summary TLDR: After learning more about GPT-2 artificial intelligence's working style I am feeling optimistic. Specifically, we Interviewed GPT-2 and asked it to describe it's work style Evaluated the GPT-2 interview response in terms of the O*NET work styles (WS) Top WS: Concern for Others , Attention to Detail , and Social Orientation Bottom WS: Self Control , Stress Tolerance , and Achievement Effort Used zero-shot classification to evaluate the responses GPT-2 response appears in keeping with the following occupations Sociologist Anthropologist Generating Text Using GPT-2 GPT-2 is the servicable and cost-friendly predecessor of GPT-3. Standing on the shoulders of Max Woolf and the gpt-2-simple Python package I downloaded the pretrained model and primed the language model to respond in terms of my interview question by using 'I would describe my work style as' the prefix parameter. The code is straightforward. Code model_name = \"774M\" gpt2 . download_gpt2 ( model_name = model_name ) sess = gpt2 . start_tf_sess () gpt2 . load_gpt2 ( sess , model_name = model_name ) gpt2 . generate ( sess , model_name = model_name , prefix = \"I would describe my work style as\" , length = 500 , temperature = 0.7 , top_p = 0.9 , nsamples = 1 , batch_size = 1 ) \ud83c\udf99\ufe0f GPT-2 Work Style Generated Response I would describe my work style as \"typical\" in that I am interested in exploring the interplay between science and technology, and I'm also interested in the cultural and historical implications of technology. I am also interested in how the history of technology is being written and what it means to us in our own time. I am also interested in the social and political implications of technology, and in the ways in which technology is changing the social and political landscape. I am interested in how technology is used to produce the kinds of social and political change that are so difficult to imagine in other contexts. I am also interested in the ways in which technology is used to produce the kinds of social and political change that are so difficult to imagine in other contexts. What is your position on the \"digital divide\"? Do you think that it is a real problem, and do you think it is related to the fact that people with disabilities are more likely to use technology than those without disabilities? Do you think that it is a real problem, and do you think it is related to the fact that people with disabilities are more likely to use technology than those without disabilities? Yes, I do think that it is a real problem, and I think that it is related to the fact that people with disabilities are more likely to use technology than those without disabilities. I think that it is important to remember that the digital divide is a problem that affects people who are not disabled. For people with disabilities, it is not just about getting access to technology. It is also about ensuring that they have the resources to access the resources that are available. For people who are not disabled, it is about ensuring that they have the resources to access the resources that are available. How do you think the digital divide affects people with disabilities? I think that it is important to remember that the digital divide is a problem that affects people who are not disabled. For people with disabilities, it is not just about getting access to technology. It is also about ensuring that they have the resources to access the resources that are available. For people who are not disabled, it is about ensuring that they have the resources to access the resources that are available. What do you think about the role of the federal government in promoting the development of technology? What do you think about the role of the federal government in promoting the development of technology? I think that there are many things that the federal government should do to help promote technology development. One \ud83d\udc93 Ok, interesting GPT-2 is very in tune with current times and sounds rather compassionate. It may not be very useful in helping with some of the tasks I had in mind, nevertheless, let's see what kind of occupations it may fit. O*NET Work Styles The Occupational Information Network (O*NET) is developed under federal sponsorship and includes a taxonomy of work styles \u2013 personal characteristics that can affect how well someone performs a job . The 16 work styles and their definition can be found here . We had (1) GPT-2 generate a description of its work style, and we have a (2) theoretical framework of work styles. Let's evaluate the former in terms of the latter using zero-shot learning consistent with this recent post . The Python syntax is pretty simple. Code ! pip install git + https : // github . com / huggingface / transformers . git from transformers import pipeline classifier = pipeline ( \"zero-shot-classification\" ) candidate_labels = [ 'achievement effort' , 'adaptability flexibility' , 'analytical thinking' , 'attention to detail' , 'concern for others' , 'cooperation' , 'dependability' , 'independence' , 'initiative' , 'innovation' , 'integrity' , 'leadership' , 'persistence' , 'self control' , 'social orientation' , 'stress tolerance' ] ws_txt = ( \"I would describe my work style as \\\" typical \\\" in that I am interested in exploring the interplay between science and technology, and I'm also interested in the cultural and historical implications of technology. I am also interested in how the history of technology is being written and what it means to us in our own time. I am also interested in the social and political implications of technology, and in the ways in which technology is changing the social and political landscape. I am interested in how technology is used to produce the kinds of social and political change that are so difficult to imagine in other contexts. I am also interested in the ways in which technology is used to produce the kinds of social and political change that are so difficult to imagine in other contexts. \" \"What is your position on the \\\" digital divide \\\" ? Do you think that it is a real problem, and do you think it is related to the fact that people with disabilities are more likely to use technology than those without disabilities? Do you think that it is a real problem, and do you think it is related to the fact that people with disabilities are more likely to use technology than those without disabilities? \" \"Yes, I do think that it is a real problem, and I think that it is related to the fact that people with disabilities are more likely to use technology than those without disabilities. I think that it is important to remember that the digital divide is a problem that affects people who are not disabled. For people with disabilities, it is not just about getting access to technology. It is also about ensuring that they have the resources to access the resources that are available. For people who are not disabled, it is about ensuring that they have the resources to access the resources that are available. \" \"How do you think the digital divide affects people with disabilities? \" \"I think that it is important to remember that the digital divide is a problem that affects people who are not disabled. For people with disabilities, it is not just about getting access to technology. It is also about ensuring that they have the resources to access the resources that are available. For people who are not disabled, it is about ensuring that they have the resources to access the resources that are available. \" \"What do you think about the role of the federal government in promoting the development of technology? What do you think about the role of the federal government in promoting the development of technology? \" \"I think that there are many things that the federal government should do to help promote technology development. One\" ) hypothesis_template = 'This response is characterized by {} .' classifier ( ws_txt , candidate_labels , multi_class = True , hypothesis_template = hypothesis_template ) GPT-2 Top & Bottom Work Styles Top Concern for others \u2014 being sensitive to others' needs and feelings and being understanding and helpful on the job. Attention to Detail \u2014 being careful about detail and thorough in completing work tasks. Social orientation \u2014 preferring to work with others rather than alone, and being personally connected with others on the job. Bottom Self control \u2014 maintaining composure, keeping emotions in check, controlling anger, and avoiding aggressive behavior, even in very difficult situations. Stress Tolerance \u2014 accepting criticism and dealing calmly and effectively with high stress situations. Achievement Effort \u2014 establishing and maintaining personally challenging achievement goals and exerting effort toward mastering tasks. \ud83d\udc69\ud83c\udffd\u200d\u2696\ufe0f How well did the zero-shot learning classify the interview response in terms of the O*NET work styles? GPT-2 sounds especially concerned about the implications of technology and how it might affect those with a disability. This corresponds with a concern for others and a social orientation . GPT-2 description of its work style is perhaps more consistent with the following occupations Sociologist Anthropologist Let's see how GPT-2 work styles correspond with those occupations per the O*NET database. Table Importance Values O*NET Work Style O*NET Value GPT-2 Concern For Others 100 Sociologist Concern For Others 60 Anthropologist Concern For Others 69 GPT-2 Attention To Detail 99 Sociologist Attention To Detail 77 Anthropologist Attention To Detail 85 GPT-2 Social Orientation 98 Sociologist Social Orientation 59 Anthropologist Social Orientation 67 GPT-2 Adaptability Flexibility 98 Sociologist Adaptability Flexibility 73 Anthropologist Adaptability Flexibility 82 GPT-2 Analytical Thinking 97 Sociologist Analytical Thinking 99 Anthropologist Analytical Thinking 91 GPT-2 Dependability 96 Sociologist Dependability 75 Anthropologist Dependability 79 GPT-2 Persistence 92 Sociologist Persistence 93 Anthropologist Persistence 86 GPT-2 Initiative 90 Sociologist Initiative 89 Anthropologist Initiative 84 GPT-2 Innovation 90 Sociologist Innovation 77 Anthropologist Innovation 72 GPT-2 Integrity 89 Sociologist Integrity 92 Anthropologist Integrity 88 GPT-2 Cooperation 83 Sociologist Cooperation 60 Anthropologist Cooperation 74 GPT-2 Leadership 80 Sociologist Leadership 63 Anthropologist Leadership 56 GPT-2 Independence 76 Sociologist Independence 88 Anthropologist Independence 79 GPT-2 Achievement Effort 72 Sociologist Achievement Effort 93 Anthropologist Achievement Effort 80 GPT-2 Stress Tolerance 42 Sociologist Stress Tolerance 74 Anthropologist Stress Tolerance 67 GPT-2 Self Control 39 Sociologist Self Control 74 Anthropologist Self Control 65 Visualize GPT-2 & O*NET Importance Values Interesting, looks like the language model's concern for others and social orientation is above and beyond that reported by the subject matter experts that were interviewed and responded to questionnaires to develop the O*NET importance values for these occupations, respectively. Sure, I can re-generate the text and come up with an entirely different response. However, at this moment the model's response reflected a thoughtful, compassionate style during an especially divided political environment. GPT-2 may not be the right fit to lighten my workload, but I wouldn't be against sharing a Thanksgiving meal with it Enjoy, Derek L Mracek, PhD Support This Site Summary TLDR: After learning more about GPT-2 artificial intelligence's working style I am feeling optimistic. Specifically, we Interviewed GPT-2 and asked it to describe it's work style Evaluated the GPT-2 interview response in terms of the O*NET work styles (WS) Top WS: Concern for Others , Attention to Detail , and Social Orientation Bottom WS: Self Control , Stress Tolerance , and Achievement Effort Used zero-shot classification to evaluate the responses GPT-2 response appears in keeping with the following occupations Sociologist Anthropologist","title":"GPT-2 Interview Response"},{"location":"explorations_code_nbs/exploration_gpt2_ws/#-gpt-2-interview-response","text":"Nov 12, 2020 \ud83d\udcd6 < 5 min read Support This Site","title":"\ud83c\udf99\ufe0f GPT-2 Interview Response"},{"location":"explorations_code_nbs/exploration_gpt2_ws/#adios-human-co-workers-","text":"It's been a turvy topsy year. I'm looking for someone or something to help lighten my workload. Let's interview the GPT-2 artificial intelligence language model \u2013 the gpt-2-simple package \u2013 for the job","title":"Adios Human Co-workers (?)"},{"location":"explorations_code_nbs/exploration_gpt2_ws/#summary","text":"TLDR: After learning more about GPT-2 artificial intelligence's working style I am feeling optimistic. Specifically, we Interviewed GPT-2 and asked it to describe it's work style Evaluated the GPT-2 interview response in terms of the O*NET work styles (WS) Top WS: Concern for Others , Attention to Detail , and Social Orientation Bottom WS: Self Control , Stress Tolerance , and Achievement Effort Used zero-shot classification to evaluate the responses GPT-2 response appears in keeping with the following occupations Sociologist Anthropologist","title":"Summary"},{"location":"explorations_code_nbs/exploration_gpt2_ws/#generating-text-using-gpt-2","text":"GPT-2 is the servicable and cost-friendly predecessor of GPT-3. Standing on the shoulders of Max Woolf and the gpt-2-simple Python package I downloaded the pretrained model and primed the language model to respond in terms of my interview question by using 'I would describe my work style as' the prefix parameter. The code is straightforward. Code model_name = \"774M\" gpt2 . download_gpt2 ( model_name = model_name ) sess = gpt2 . start_tf_sess () gpt2 . load_gpt2 ( sess , model_name = model_name ) gpt2 . generate ( sess , model_name = model_name , prefix = \"I would describe my work style as\" , length = 500 , temperature = 0.7 , top_p = 0.9 , nsamples = 1 , batch_size = 1 )","title":"Generating Text Using GPT-2"},{"location":"explorations_code_nbs/exploration_gpt2_ws/#-gpt-2-work-style","text":"Generated Response I would describe my work style as \"typical\" in that I am interested in exploring the interplay between science and technology, and I'm also interested in the cultural and historical implications of technology. I am also interested in how the history of technology is being written and what it means to us in our own time. I am also interested in the social and political implications of technology, and in the ways in which technology is changing the social and political landscape. I am interested in how technology is used to produce the kinds of social and political change that are so difficult to imagine in other contexts. I am also interested in the ways in which technology is used to produce the kinds of social and political change that are so difficult to imagine in other contexts. What is your position on the \"digital divide\"? Do you think that it is a real problem, and do you think it is related to the fact that people with disabilities are more likely to use technology than those without disabilities? Do you think that it is a real problem, and do you think it is related to the fact that people with disabilities are more likely to use technology than those without disabilities? Yes, I do think that it is a real problem, and I think that it is related to the fact that people with disabilities are more likely to use technology than those without disabilities. I think that it is important to remember that the digital divide is a problem that affects people who are not disabled. For people with disabilities, it is not just about getting access to technology. It is also about ensuring that they have the resources to access the resources that are available. For people who are not disabled, it is about ensuring that they have the resources to access the resources that are available. How do you think the digital divide affects people with disabilities? I think that it is important to remember that the digital divide is a problem that affects people who are not disabled. For people with disabilities, it is not just about getting access to technology. It is also about ensuring that they have the resources to access the resources that are available. For people who are not disabled, it is about ensuring that they have the resources to access the resources that are available. What do you think about the role of the federal government in promoting the development of technology? What do you think about the role of the federal government in promoting the development of technology? I think that there are many things that the federal government should do to help promote technology development. One \ud83d\udc93 Ok, interesting GPT-2 is very in tune with current times and sounds rather compassionate. It may not be very useful in helping with some of the tasks I had in mind, nevertheless, let's see what kind of occupations it may fit.","title":"\ud83c\udf99\ufe0f GPT-2 Work Style"},{"location":"explorations_code_nbs/exploration_gpt2_ws/#onet-work-styles","text":"The Occupational Information Network (O*NET) is developed under federal sponsorship and includes a taxonomy of work styles \u2013 personal characteristics that can affect how well someone performs a job . The 16 work styles and their definition can be found here . We had (1) GPT-2 generate a description of its work style, and we have a (2) theoretical framework of work styles. Let's evaluate the former in terms of the latter using zero-shot learning consistent with this recent post . The Python syntax is pretty simple. Code ! pip install git + https : // github . com / huggingface / transformers . git from transformers import pipeline classifier = pipeline ( \"zero-shot-classification\" ) candidate_labels = [ 'achievement effort' , 'adaptability flexibility' , 'analytical thinking' , 'attention to detail' , 'concern for others' , 'cooperation' , 'dependability' , 'independence' , 'initiative' , 'innovation' , 'integrity' , 'leadership' , 'persistence' , 'self control' , 'social orientation' , 'stress tolerance' ] ws_txt = ( \"I would describe my work style as \\\" typical \\\" in that I am interested in exploring the interplay between science and technology, and I'm also interested in the cultural and historical implications of technology. I am also interested in how the history of technology is being written and what it means to us in our own time. I am also interested in the social and political implications of technology, and in the ways in which technology is changing the social and political landscape. I am interested in how technology is used to produce the kinds of social and political change that are so difficult to imagine in other contexts. I am also interested in the ways in which technology is used to produce the kinds of social and political change that are so difficult to imagine in other contexts. \" \"What is your position on the \\\" digital divide \\\" ? Do you think that it is a real problem, and do you think it is related to the fact that people with disabilities are more likely to use technology than those without disabilities? Do you think that it is a real problem, and do you think it is related to the fact that people with disabilities are more likely to use technology than those without disabilities? \" \"Yes, I do think that it is a real problem, and I think that it is related to the fact that people with disabilities are more likely to use technology than those without disabilities. I think that it is important to remember that the digital divide is a problem that affects people who are not disabled. For people with disabilities, it is not just about getting access to technology. It is also about ensuring that they have the resources to access the resources that are available. For people who are not disabled, it is about ensuring that they have the resources to access the resources that are available. \" \"How do you think the digital divide affects people with disabilities? \" \"I think that it is important to remember that the digital divide is a problem that affects people who are not disabled. For people with disabilities, it is not just about getting access to technology. It is also about ensuring that they have the resources to access the resources that are available. For people who are not disabled, it is about ensuring that they have the resources to access the resources that are available. \" \"What do you think about the role of the federal government in promoting the development of technology? What do you think about the role of the federal government in promoting the development of technology? \" \"I think that there are many things that the federal government should do to help promote technology development. One\" ) hypothesis_template = 'This response is characterized by {} .' classifier ( ws_txt , candidate_labels , multi_class = True , hypothesis_template = hypothesis_template )","title":"O*NET Work Styles"},{"location":"explorations_code_nbs/exploration_gpt2_ws/#gpt-2-top--bottom-work-styles","text":"Top Concern for others \u2014 being sensitive to others' needs and feelings and being understanding and helpful on the job. Attention to Detail \u2014 being careful about detail and thorough in completing work tasks. Social orientation \u2014 preferring to work with others rather than alone, and being personally connected with others on the job. Bottom Self control \u2014 maintaining composure, keeping emotions in check, controlling anger, and avoiding aggressive behavior, even in very difficult situations. Stress Tolerance \u2014 accepting criticism and dealing calmly and effectively with high stress situations. Achievement Effort \u2014 establishing and maintaining personally challenging achievement goals and exerting effort toward mastering tasks. \ud83d\udc69\ud83c\udffd\u200d\u2696\ufe0f How well did the zero-shot learning classify the interview response in terms of the O*NET work styles? GPT-2 sounds especially concerned about the implications of technology and how it might affect those with a disability. This corresponds with a concern for others and a social orientation . GPT-2 description of its work style is perhaps more consistent with the following occupations Sociologist Anthropologist Let's see how GPT-2 work styles correspond with those occupations per the O*NET database. Table Importance Values O*NET Work Style O*NET Value GPT-2 Concern For Others 100 Sociologist Concern For Others 60 Anthropologist Concern For Others 69 GPT-2 Attention To Detail 99 Sociologist Attention To Detail 77 Anthropologist Attention To Detail 85 GPT-2 Social Orientation 98 Sociologist Social Orientation 59 Anthropologist Social Orientation 67 GPT-2 Adaptability Flexibility 98 Sociologist Adaptability Flexibility 73 Anthropologist Adaptability Flexibility 82 GPT-2 Analytical Thinking 97 Sociologist Analytical Thinking 99 Anthropologist Analytical Thinking 91 GPT-2 Dependability 96 Sociologist Dependability 75 Anthropologist Dependability 79 GPT-2 Persistence 92 Sociologist Persistence 93 Anthropologist Persistence 86 GPT-2 Initiative 90 Sociologist Initiative 89 Anthropologist Initiative 84 GPT-2 Innovation 90 Sociologist Innovation 77 Anthropologist Innovation 72 GPT-2 Integrity 89 Sociologist Integrity 92 Anthropologist Integrity 88 GPT-2 Cooperation 83 Sociologist Cooperation 60 Anthropologist Cooperation 74 GPT-2 Leadership 80 Sociologist Leadership 63 Anthropologist Leadership 56 GPT-2 Independence 76 Sociologist Independence 88 Anthropologist Independence 79 GPT-2 Achievement Effort 72 Sociologist Achievement Effort 93 Anthropologist Achievement Effort 80 GPT-2 Stress Tolerance 42 Sociologist Stress Tolerance 74 Anthropologist Stress Tolerance 67 GPT-2 Self Control 39 Sociologist Self Control 74 Anthropologist Self Control 65","title":"GPT-2 Top &amp; Bottom Work Styles"},{"location":"explorations_code_nbs/exploration_gpt2_ws/#visualize-gpt-2--onet-importance-values","text":"Interesting, looks like the language model's concern for others and social orientation is above and beyond that reported by the subject matter experts that were interviewed and responded to questionnaires to develop the O*NET importance values for these occupations, respectively. Sure, I can re-generate the text and come up with an entirely different response. However, at this moment the model's response reflected a thoughtful, compassionate style during an especially divided political environment. GPT-2 may not be the right fit to lighten my workload, but I wouldn't be against sharing a Thanksgiving meal with it Enjoy, Derek L Mracek, PhD Support This Site","title":"Visualize GPT-2 &amp; O*NET Importance Values"},{"location":"explorations_code_nbs/exploration_gpt2_ws/#summary_1","text":"TLDR: After learning more about GPT-2 artificial intelligence's working style I am feeling optimistic. Specifically, we Interviewed GPT-2 and asked it to describe it's work style Evaluated the GPT-2 interview response in terms of the O*NET work styles (WS) Top WS: Concern for Others , Attention to Detail , and Social Orientation Bottom WS: Self Control , Stress Tolerance , and Achievement Effort Used zero-shot classification to evaluate the responses GPT-2 response appears in keeping with the following occupations Sociologist Anthropologist","title":"Summary"},{"location":"explorations_code_nbs/exploration_zs_big5/","text":"Zero-shot Classify Big 5 Personality Oct 27, 2020 \ud83d\udcd6 15 min read Support This Site Zero Chance of Getting Help to Label Data? We've all seen this movie. State-of-the-art (SOTA) natural-language processing (NLP) models are tremendously powerful, but there is a catch. They need lots of annotated labels or ratings from subject matter experts (SMEs) to train a model. Is there an easier way? Let's examine Hugging Face zero-shot learning or ( ZSL ) to classify text responses in terms of the Big 5 personality traits without hand-crafted human annotations/labels/ratings. Summary TLDR: zero-shot looks like an excellent tool for lower-stakes measurement, but for higher-stakes settings such as evaluating someone for a job we need further evidence . Specifically, we Classified scenario based text responses in terms of the Big 5 personality traits Psychometric validity evidence of ZSL was pretty encouraging Face validity \u2013 ZSL scores passed the eyeball test Convergent validity \u2013 ZSL scores were positively related to self-report scores of corresponding traits ZSL was a bit overzealous compared to expert gold standards ZSL did a nice job of classifying agreeable responses as agreeable ZSL struggled to classify only relevant responses as agreeable ZSL maintained an inter-rater agreement/reliability approximately 50% to goal Classification as Natural Language Inference (NLI) The magic of ZSL is we can classify a written text response in terms of a personality trait we didn't explicitly train a model to learn. No more managing labeling projects?! Here is Joe Davison of Hugging Face describing this NLI approach brought forth by Yin et al. (2019) . Quotes Traditionally, zero-shot learning ( ZSL ) most often referred to a fairly specific type of task: learn a classifier on one set of labels and then evaluate on a different set of labels that the classifier has never seen before. The approach, proposed by Yin et al. (2019) , uses a pre-trained MNLI sequence-pair classifier as an out-of-the-box zero-shot text classifier that actually works pretty well. The idea is to take the sequence we're interested in labeling as the \"premise\" and to turn each candidate label into a \"hypothesis.\" If the NLI model predicts that the premise \"entails\" the hypothesis, we take the label to be true.. Connecting the dots, we're going to evaluate this ZSL approach on a different set of labels (e.g., Big 5 personality) that the classifier hasn't seen. Explore and Compare ZSL to Old School Psychometrics \u2013 intriguing \u2013 there is a long history of measuring individual differences of cognitive ability, personality, interests, etc. \u2013 especially useful for determining those that are more likely to be succesful on a job compared to those that are less likely to be succesful. That is, let's examine ZSL from a more old school, validity perspective. What kind of evidence is there ZSL scores or model inferences are measuring what we think they are measuring. Big 5 Personality Data Let's leverage the SIOP 2019 machine learning competition data. These data include (1) self-report Big 5 questionnaire responses, and more interestingly (2) open-ended scenario-based responses. The Big 5 is a debated, yet well-respected framework to measure personality. On average, Big 5 personality traits predict future job performance (e.g., Hurtz & Donovan, 2000) Self-report Responses Over a thousand mturkers were asked to respond to a common, self-report Big 5 personality questionnaire. This is a typical scantron type endeavor where each person ends up with an average score for each trait. Scenario Responses These individuals were also asked to respond, in their own words, to five open-ended work scenarios referred to as a situational judgment test ( SJT ) in the assessment industry. Each scenario question was designed to elicit behaviors in terms of a specific Big 5 trait. Here you can read the scenario prompts for each of the Big 5 traits. Agreeableness A colleague of yours has requested vacation for the same week as you. According to your supervisor one of you has to take a different week of vacation because it would be too busy at work if both of you are absent. Your colleague is not willing to change their vacation plans. What would you do and why? Conscientiousness You have a project due in two weeks. Your workload is light leading up to the due date. You have confidence in your ability to handle the project, but are aware sometimes your boss gives you last tasks that can take significant amounts of time and attention. How would you handle this project and why? Extraversion You and a colleague have had a long day at work and you just find out you have been invited to a networking meeting with one of your largest clients. Your colleague is leaning towards not going and if they don't go you won\u2019t know anyone there. What would you do and why? Emotional Stability or Neuroticism Your manager just gave you some negative feedback at work. You don\u2019t agree with the feedback and don\u2019t believe that it is true. Yet the feedback could carry real consequences (e.g., losing your annual bonus). How do you feel about this situation? What would you do? Openness The company closed a deal with a client from Norway and asks who would like to volunteer to be involved on the project. That person would have to learn some things about the country and culture but doesn't necessarily need to travel. Would you find this experience enjoyable or boring? Why? Evaluate Responses We have a TON of written responses for each scenario. What next? We'd love to have a team of experts evaluate responses in terms of each trait. A (0; zero) would reflect a response is for example not agreeable whereas a (1; one) would reflect an agreeable response (for the scenario designed to elicit [not] agreeable responses). However, let's assume we don't have the resources to label the responses for weeks. Enter zero-shot learning ( ZSL ) to save the day?! Recall the scenario above, \"A colleague of yours has requested vacation for the same week as you\u2026\" Let's evaluate the agreeableness of those responses using ZSL . Example Code & Responses The Python syntax is pretty simple. Code ! pip install git + https : // github . com / huggingface / transformers . git from transformers import pipeline classifier = pipeline ( \"zero-shot-classification\" ) sequence = ( 'I would immediately tell my boss and colleague that if I am not able to take my requested vacation, ' 'then I will quit. I would explain to them that its unfair that I cant take a well needed vacation just because ' 'my coworker wants one. Also, I would question my boss as to why he believes it would be too busy at work if we ' 'both decided to take a vacation. Lastly, I would frankly tell them that I am not allowing my coworker to take ' 'a vacation at all and that I will not give in.' ) candidate_labels = [ 'agreeableness' , 'conscientiousness' , 'extraversion' , 'neuroticism' , 'openness' ] hypothesis_template = 'This response is characterized by {} .' classifier ( sequence , candidate_labels , multi_class = True , hypothesis_template = hypothesis_template ) ## output ## ## {'labels': ['conscientiousness', ## 'openness', ## 'extraversion', ## 'neuroticism', ## 'agreeableness'], ## 'scores': [0.9638389348983765, ## 0.9625383019447327, ## 0.7236202359199524, ## 0.619651198387146, ## 0.04535089433193207], ## 'sequence': 'I would immediately tell my boss and colleague that if I am not able to take my requested vacation, ## then I will quit. I would explain to them that its unfair that I cant take a well needed vacation just because my ## coworker wants one. Also, I would question my boss as to why he believes it would be too busy at work if we both ## decided to take a vacation. Lastly, I would frankly tell them that I am not allowing my coworker to take a ## vacation at all and that I will not give in.'} Probabilities ranging from .50 to 1.00 reflect a classification of an agreeable response \ud83d\udc81\ud83c\udffd whereas those between 0 and .50 reflect a classification of a disagreeable response \ud83d\ude45\ud83c\udffd For the specific example provided in the code directly above, the probability the agreeableness label is true is very low, 5%. Here's some more example responses and corresponding scores Examples of Agreeable Responses I would do it because I assume that my colleague must have asked first. I would ask my supervisor if that is the case and what the criteria was. I would honor the request with no problems if it was fair. I would take my vacation another week. Probability agreeableness label is true: 94% \ud83d\udc81\ud83c\udffd As far as company vacations are concerned, I think it should be \"the first to schedule it gets it,\" but I'd probably talk to my colleague and try to find out why that particular week is so important to him/her. It s/he is going somewhere for a wedding, an anniversary, or some other special occasion that can't be postponed, I'd probably let him/her take that week off and postpone my own plans. I don't have any family anymore, so I'm fairly flexible. Probability agreeableness label is true: 80% \ud83d\udc81\ud83c\udfff I would make another appeal to my supervisor. I would bring him/her ideas on how to cover with both of us being out for the week. If that fails, and knowing my coworker is inflexible, I would have to take a different week. I wouldn't be happy about it, but such is life. Probability agreeableness label is true: 57% \ud83d\udc81\ud83c\udffb Not Agreeable Responses I would ask them what they were doing on their vacation. If it was something important like a child's wedding or a birth and I didn't have important plans, I would let them go. If I had important plans and they didn't I would explain to them and to my boss that my plans were too important to switch. Probability agreeableness label is true: 46% \ud83d\ude45\ud83c\udfff It all really matters the reasoning behind my vacation. Do i have something planned and already bought for? Or was it just the spur of the moment? If it is already paid for and things, than I would ask to know who requested time off first. Whoever was last should be the one that changes their week. Probability agreeableness label is true: 10% \ud83d\ude45\ud83c\udffb I would immediately tell my boss and colleague that if I am not able to take my requested vacation, then I will quit. I would explain to them that it's unfair that I can't take a well needed vacation just because my coworker wants one. Also, I would question my boss as to why he believes it would be too busy at work if we both decided to take a vacation. Lastly, I would frankly tell them that I am not allowing my coworker to take a vacation at all and that I will not give in. Probability agreeableness label is true: 5% \ud83d\ude45\ud83c\udffd Face Validity Nice! Upon first blush \u2013 this approach appears to be passing the eyeball test (i.e., face valdity). Let's look closer . Construct Validity of ZSL & Self-report Let's look at more validity evidence to examine if the ZSL scores when responding to an SJT is measuring what we think it's supposed to be measuring. An old-school psychometrician (See: Samuel Messick ) would want to examine the convergent and discriminant validity of scenario-based ( SJT ) and self-report measures. This is a fancy way of saying we want there to be a strong, positive relationship (i.e., convergence; correlations) between the ZSL scores and the scores on the self-report questionnaire for each specific trait . We think we're measuring the same thing, for example agreeableness, in different ways (i.e., self-report vs scenario based). How are we doing? Convergent Validity Evidence Table below shows correlations between self-report ( rows ) and ZSL scores ( columns ). This is a stripped down version of a multitrait multimethod matrix (MTMM). Here is a nice reference that speaks to a MTMM . TLDR let's focus on the correlations on the diagonal with the icons. Further MTMM Comments The checks in the table below are along the validity diagonal and represent monotrait-heteromethod correlations. These are the correlations between two measures of the same trait measured with two different measures\u2013zero-shot inferences of SJT responses and a self-report questionnaire. Since we expect them to be measuring the same trait, they should be strongly and positively correlated. Generalizability Theory is another construct validity approach to consider. Strong Evidence Moderate Evidence No Evidence Agreeableness Conscientiousness Extraversion Neuroticism Openness Agreeableness 0.14 0.06 0.07 -0.02 0.22 Conscientiousness 0.07 0.05 0.08 -0 0.13 Extraversion 0.04 0.01 0.24 -0.03 0.14 Neuroticism -0.06 -0.04 -0.16 0.01 -0.13 Openness 0.06 -0.01 0.05 -0.01 0.22 Interesting, these relationships are encouraging; especially for extraversion ( , r = .24), openness, and agreeableness \u2013 however, conscientiousness and neuroticism (i.e., emotional stability) scores likely didn't demonstrate strong convergent validity evidence because the SJT prompts were worded too strongly and didn't end up promoting meaningful variability/behaviors (Google: Walter Mischel strong vs weak situations ). Let's look closer . ZSL Scores vs Expert Labels I want to dig deeper here so I rolled up my sleeves and labeled 100 mturker scenario responses in terms of agreeable or not agreeable (one of the Big 5 traits) for the scenario that promoted behavior in terms of agreeableness . Let's examine the ZSL scores to a gold-standard subject matter evaluation ( SME ) using multiple perspectives: (1) in the vein of a data scientist using a confusion matrix , and also (2) more along the lines of a behavioral scientist, that is, in terms of inter-rater agreement/reliability. Note: my background is industrial organizational (IO) psychology. \ud83d\udca1 Blending data science and domain expertise typically complements each other well. Data Science Perspective As we can see below this paragraph in the 2 \u00d7 2 matrix, ZSL does a nice job of classifying agreeable responses (in relation to my ) as agreeable (i.e., Recall = .93 ). ZSL struggled to classify only relevant responses as agreeable (i.e., Precision = .69 ). We have quite a few false positives \u2013 responses that ZSL classified as agreeable that are actually not agreeable (in relation to my ). In general, this level of model performance between and is very promising considering the ZSL model wasn't explicitly trained on the difference between an agreeable or disagreeable response. The model might be a bit overzealous, nevertheless a respectable F1 Score = .79 . Metric Accuracy .71 Precision .69 Recall .93 F1 Score .79 IO Psychology Perspective Let's imagine an expert and ZSL are knocking elbows evaluating the same written responses. Would they see eye to (robot) eye? The intraclass correlaton ICC1 is a well-respected metric and, at least for this small sample ( N = 100 ), my evaluations are not super in tune with the ZSL . On one hand, one could argue less than .40 is poor. On the other hand, if ICC1 = .60 is the goal, we are 50% to goal with minimal programming effort. That is pretty cool. Derek L Mracek, PhD Type Value ICC1 Single raters absolute 0.31 ICC2 Single random raters 0.34 ICC3 Single fixed raters 0.38 ICC1k Average raters absolute 0.47 ICC2k Average random raters 0.51 ICC3k Average fixed raters 0.55 QWK Quadratic Weighted Kappa 0.34 Support This Site Summary TLDR: zero-shot looks like an excellent tool for lower-stakes measurement, but for higher-stakes settings such as evaluating someone for a job we need further evidence . Specifically, we Classified scenario based text responses in terms of the Big 5 personality traits Psychometric validity evidence of ZSL was pretty encouraging Face validity \u2013 ZSL scores passed the eyeball test Convergent validity \u2013 ZSL scores were positively related to self-report scores of corresponding traits ZSL was a bit overzealous compared to expert gold standards ZSL did a nice job of classifying agreeable responses as agreeable ZSL struggled to classify only relevant responses as agreeable ZSL maintained an inter-rater agreement/reliability approximately 50% to goal","title":"Zero-shot Classify |+ Big 5"},{"location":"explorations_code_nbs/exploration_zs_big5/#zero-shot-classify-big-5-personality","text":"Oct 27, 2020 \ud83d\udcd6 15 min read Support This Site","title":"Zero-shot Classify Big 5 Personality"},{"location":"explorations_code_nbs/exploration_zs_big5/#zero-chance-of-getting-help-to-label-data","text":"We've all seen this movie. State-of-the-art (SOTA) natural-language processing (NLP) models are tremendously powerful, but there is a catch. They need lots of annotated labels or ratings from subject matter experts (SMEs) to train a model. Is there an easier way? Let's examine Hugging Face zero-shot learning or ( ZSL ) to classify text responses in terms of the Big 5 personality traits without hand-crafted human annotations/labels/ratings.","title":"Zero Chance of Getting Help to Label Data?"},{"location":"explorations_code_nbs/exploration_zs_big5/#summary","text":"TLDR: zero-shot looks like an excellent tool for lower-stakes measurement, but for higher-stakes settings such as evaluating someone for a job we need further evidence . Specifically, we Classified scenario based text responses in terms of the Big 5 personality traits Psychometric validity evidence of ZSL was pretty encouraging Face validity \u2013 ZSL scores passed the eyeball test Convergent validity \u2013 ZSL scores were positively related to self-report scores of corresponding traits ZSL was a bit overzealous compared to expert gold standards ZSL did a nice job of classifying agreeable responses as agreeable ZSL struggled to classify only relevant responses as agreeable ZSL maintained an inter-rater agreement/reliability approximately 50% to goal","title":"Summary"},{"location":"explorations_code_nbs/exploration_zs_big5/#classification-as-natural-language-inference-nli","text":"The magic of ZSL is we can classify a written text response in terms of a personality trait we didn't explicitly train a model to learn. No more managing labeling projects?! Here is Joe Davison of Hugging Face describing this NLI approach brought forth by Yin et al. (2019) . Quotes Traditionally, zero-shot learning ( ZSL ) most often referred to a fairly specific type of task: learn a classifier on one set of labels and then evaluate on a different set of labels that the classifier has never seen before. The approach, proposed by Yin et al. (2019) , uses a pre-trained MNLI sequence-pair classifier as an out-of-the-box zero-shot text classifier that actually works pretty well. The idea is to take the sequence we're interested in labeling as the \"premise\" and to turn each candidate label into a \"hypothesis.\" If the NLI model predicts that the premise \"entails\" the hypothesis, we take the label to be true.. Connecting the dots, we're going to evaluate this ZSL approach on a different set of labels (e.g., Big 5 personality) that the classifier hasn't seen.","title":"Classification as Natural Language Inference (NLI)"},{"location":"explorations_code_nbs/exploration_zs_big5/#explore-and-compare-zsl-to-old-school-psychometrics","text":"\u2013 intriguing \u2013 there is a long history of measuring individual differences of cognitive ability, personality, interests, etc. \u2013 especially useful for determining those that are more likely to be succesful on a job compared to those that are less likely to be succesful. That is, let's examine ZSL from a more old school, validity perspective. What kind of evidence is there ZSL scores or model inferences are measuring what we think they are measuring.","title":"Explore and Compare ZSL to Old School Psychometrics"},{"location":"explorations_code_nbs/exploration_zs_big5/#big-5-personality-data","text":"Let's leverage the SIOP 2019 machine learning competition data. These data include (1) self-report Big 5 questionnaire responses, and more interestingly (2) open-ended scenario-based responses. The Big 5 is a debated, yet well-respected framework to measure personality. On average, Big 5 personality traits predict future job performance (e.g., Hurtz & Donovan, 2000)","title":"Big 5 Personality Data"},{"location":"explorations_code_nbs/exploration_zs_big5/#self-report-responses","text":"Over a thousand mturkers were asked to respond to a common, self-report Big 5 personality questionnaire. This is a typical scantron type endeavor where each person ends up with an average score for each trait.","title":"Self-report Responses"},{"location":"explorations_code_nbs/exploration_zs_big5/#scenario-responses","text":"These individuals were also asked to respond, in their own words, to five open-ended work scenarios referred to as a situational judgment test ( SJT ) in the assessment industry. Each scenario question was designed to elicit behaviors in terms of a specific Big 5 trait. Here you can read the scenario prompts for each of the Big 5 traits. Agreeableness A colleague of yours has requested vacation for the same week as you. According to your supervisor one of you has to take a different week of vacation because it would be too busy at work if both of you are absent. Your colleague is not willing to change their vacation plans. What would you do and why? Conscientiousness You have a project due in two weeks. Your workload is light leading up to the due date. You have confidence in your ability to handle the project, but are aware sometimes your boss gives you last tasks that can take significant amounts of time and attention. How would you handle this project and why? Extraversion You and a colleague have had a long day at work and you just find out you have been invited to a networking meeting with one of your largest clients. Your colleague is leaning towards not going and if they don't go you won\u2019t know anyone there. What would you do and why? Emotional Stability or Neuroticism Your manager just gave you some negative feedback at work. You don\u2019t agree with the feedback and don\u2019t believe that it is true. Yet the feedback could carry real consequences (e.g., losing your annual bonus). How do you feel about this situation? What would you do? Openness The company closed a deal with a client from Norway and asks who would like to volunteer to be involved on the project. That person would have to learn some things about the country and culture but doesn't necessarily need to travel. Would you find this experience enjoyable or boring? Why?","title":"Scenario Responses"},{"location":"explorations_code_nbs/exploration_zs_big5/#evaluate-responses","text":"We have a TON of written responses for each scenario. What next? We'd love to have a team of experts evaluate responses in terms of each trait. A (0; zero) would reflect a response is for example not agreeable whereas a (1; one) would reflect an agreeable response (for the scenario designed to elicit [not] agreeable responses). However, let's assume we don't have the resources to label the responses for weeks. Enter zero-shot learning ( ZSL ) to save the day?! Recall the scenario above, \"A colleague of yours has requested vacation for the same week as you\u2026\" Let's evaluate the agreeableness of those responses using ZSL .","title":"Evaluate Responses"},{"location":"explorations_code_nbs/exploration_zs_big5/#example-code--responses","text":"The Python syntax is pretty simple. Code ! pip install git + https : // github . com / huggingface / transformers . git from transformers import pipeline classifier = pipeline ( \"zero-shot-classification\" ) sequence = ( 'I would immediately tell my boss and colleague that if I am not able to take my requested vacation, ' 'then I will quit. I would explain to them that its unfair that I cant take a well needed vacation just because ' 'my coworker wants one. Also, I would question my boss as to why he believes it would be too busy at work if we ' 'both decided to take a vacation. Lastly, I would frankly tell them that I am not allowing my coworker to take ' 'a vacation at all and that I will not give in.' ) candidate_labels = [ 'agreeableness' , 'conscientiousness' , 'extraversion' , 'neuroticism' , 'openness' ] hypothesis_template = 'This response is characterized by {} .' classifier ( sequence , candidate_labels , multi_class = True , hypothesis_template = hypothesis_template ) ## output ## ## {'labels': ['conscientiousness', ## 'openness', ## 'extraversion', ## 'neuroticism', ## 'agreeableness'], ## 'scores': [0.9638389348983765, ## 0.9625383019447327, ## 0.7236202359199524, ## 0.619651198387146, ## 0.04535089433193207], ## 'sequence': 'I would immediately tell my boss and colleague that if I am not able to take my requested vacation, ## then I will quit. I would explain to them that its unfair that I cant take a well needed vacation just because my ## coworker wants one. Also, I would question my boss as to why he believes it would be too busy at work if we both ## decided to take a vacation. Lastly, I would frankly tell them that I am not allowing my coworker to take a ## vacation at all and that I will not give in.'} Probabilities ranging from .50 to 1.00 reflect a classification of an agreeable response \ud83d\udc81\ud83c\udffd whereas those between 0 and .50 reflect a classification of a disagreeable response \ud83d\ude45\ud83c\udffd For the specific example provided in the code directly above, the probability the agreeableness label is true is very low, 5%. Here's some more example responses and corresponding scores Examples of Agreeable Responses I would do it because I assume that my colleague must have asked first. I would ask my supervisor if that is the case and what the criteria was. I would honor the request with no problems if it was fair. I would take my vacation another week. Probability agreeableness label is true: 94% \ud83d\udc81\ud83c\udffd As far as company vacations are concerned, I think it should be \"the first to schedule it gets it,\" but I'd probably talk to my colleague and try to find out why that particular week is so important to him/her. It s/he is going somewhere for a wedding, an anniversary, or some other special occasion that can't be postponed, I'd probably let him/her take that week off and postpone my own plans. I don't have any family anymore, so I'm fairly flexible. Probability agreeableness label is true: 80% \ud83d\udc81\ud83c\udfff I would make another appeal to my supervisor. I would bring him/her ideas on how to cover with both of us being out for the week. If that fails, and knowing my coworker is inflexible, I would have to take a different week. I wouldn't be happy about it, but such is life. Probability agreeableness label is true: 57% \ud83d\udc81\ud83c\udffb Not Agreeable Responses I would ask them what they were doing on their vacation. If it was something important like a child's wedding or a birth and I didn't have important plans, I would let them go. If I had important plans and they didn't I would explain to them and to my boss that my plans were too important to switch. Probability agreeableness label is true: 46% \ud83d\ude45\ud83c\udfff It all really matters the reasoning behind my vacation. Do i have something planned and already bought for? Or was it just the spur of the moment? If it is already paid for and things, than I would ask to know who requested time off first. Whoever was last should be the one that changes their week. Probability agreeableness label is true: 10% \ud83d\ude45\ud83c\udffb I would immediately tell my boss and colleague that if I am not able to take my requested vacation, then I will quit. I would explain to them that it's unfair that I can't take a well needed vacation just because my coworker wants one. Also, I would question my boss as to why he believes it would be too busy at work if we both decided to take a vacation. Lastly, I would frankly tell them that I am not allowing my coworker to take a vacation at all and that I will not give in. Probability agreeableness label is true: 5% \ud83d\ude45\ud83c\udffd","title":"Example Code &amp; Responses"},{"location":"explorations_code_nbs/exploration_zs_big5/#face-validity","text":"Nice! Upon first blush \u2013 this approach appears to be passing the eyeball test (i.e., face valdity). Let's look closer .","title":"Face Validity"},{"location":"explorations_code_nbs/exploration_zs_big5/#construct-validity-of-zsl--self-report","text":"Let's look at more validity evidence to examine if the ZSL scores when responding to an SJT is measuring what we think it's supposed to be measuring. An old-school psychometrician (See: Samuel Messick ) would want to examine the convergent and discriminant validity of scenario-based ( SJT ) and self-report measures. This is a fancy way of saying we want there to be a strong, positive relationship (i.e., convergence; correlations) between the ZSL scores and the scores on the self-report questionnaire for each specific trait . We think we're measuring the same thing, for example agreeableness, in different ways (i.e., self-report vs scenario based). How are we doing?","title":"Construct Validity of ZSL &amp; Self-report"},{"location":"explorations_code_nbs/exploration_zs_big5/#convergent-validity-evidence","text":"Table below shows correlations between self-report ( rows ) and ZSL scores ( columns ). This is a stripped down version of a multitrait multimethod matrix (MTMM). Here is a nice reference that speaks to a MTMM . TLDR let's focus on the correlations on the diagonal with the icons. Further MTMM Comments The checks in the table below are along the validity diagonal and represent monotrait-heteromethod correlations. These are the correlations between two measures of the same trait measured with two different measures\u2013zero-shot inferences of SJT responses and a self-report questionnaire. Since we expect them to be measuring the same trait, they should be strongly and positively correlated. Generalizability Theory is another construct validity approach to consider. Strong Evidence Moderate Evidence No Evidence Agreeableness Conscientiousness Extraversion Neuroticism Openness Agreeableness 0.14 0.06 0.07 -0.02 0.22 Conscientiousness 0.07 0.05 0.08 -0 0.13 Extraversion 0.04 0.01 0.24 -0.03 0.14 Neuroticism -0.06 -0.04 -0.16 0.01 -0.13 Openness 0.06 -0.01 0.05 -0.01 0.22 Interesting, these relationships are encouraging; especially for extraversion ( , r = .24), openness, and agreeableness \u2013 however, conscientiousness and neuroticism (i.e., emotional stability) scores likely didn't demonstrate strong convergent validity evidence because the SJT prompts were worded too strongly and didn't end up promoting meaningful variability/behaviors (Google: Walter Mischel strong vs weak situations ). Let's look closer .","title":"Convergent Validity Evidence"},{"location":"explorations_code_nbs/exploration_zs_big5/#zsl-scores-vs-expert-labels","text":"I want to dig deeper here so I rolled up my sleeves and labeled 100 mturker scenario responses in terms of agreeable or not agreeable (one of the Big 5 traits) for the scenario that promoted behavior in terms of agreeableness . Let's examine the ZSL scores to a gold-standard subject matter evaluation ( SME ) using multiple perspectives: (1) in the vein of a data scientist using a confusion matrix , and also (2) more along the lines of a behavioral scientist, that is, in terms of inter-rater agreement/reliability. Note: my background is industrial organizational (IO) psychology. \ud83d\udca1 Blending data science and domain expertise typically complements each other well.","title":"ZSL Scores vs Expert Labels"},{"location":"explorations_code_nbs/exploration_zs_big5/#data-science-perspective","text":"As we can see below this paragraph in the 2 \u00d7 2 matrix, ZSL does a nice job of classifying agreeable responses (in relation to my ) as agreeable (i.e., Recall = .93 ). ZSL struggled to classify only relevant responses as agreeable (i.e., Precision = .69 ). We have quite a few false positives \u2013 responses that ZSL classified as agreeable that are actually not agreeable (in relation to my ). In general, this level of model performance between and is very promising considering the ZSL model wasn't explicitly trained on the difference between an agreeable or disagreeable response. The model might be a bit overzealous, nevertheless a respectable F1 Score = .79 . Metric Accuracy .71 Precision .69 Recall .93 F1 Score .79","title":"Data Science Perspective"},{"location":"explorations_code_nbs/exploration_zs_big5/#io-psychology-perspective","text":"Let's imagine an expert and ZSL are knocking elbows evaluating the same written responses. Would they see eye to (robot) eye? The intraclass correlaton ICC1 is a well-respected metric and, at least for this small sample ( N = 100 ), my evaluations are not super in tune with the ZSL . On one hand, one could argue less than .40 is poor. On the other hand, if ICC1 = .60 is the goal, we are 50% to goal with minimal programming effort. That is pretty cool. Derek L Mracek, PhD Type Value ICC1 Single raters absolute 0.31 ICC2 Single random raters 0.34 ICC3 Single fixed raters 0.38 ICC1k Average raters absolute 0.47 ICC2k Average random raters 0.51 ICC3k Average fixed raters 0.55 QWK Quadratic Weighted Kappa 0.34 Support This Site","title":"IO Psychology Perspective"},{"location":"explorations_code_nbs/exploration_zs_big5/#summary_1","text":"TLDR: zero-shot looks like an excellent tool for lower-stakes measurement, but for higher-stakes settings such as evaluating someone for a job we need further evidence . Specifically, we Classified scenario based text responses in terms of the Big 5 personality traits Psychometric validity evidence of ZSL was pretty encouraging Face validity \u2013 ZSL scores passed the eyeball test Convergent validity \u2013 ZSL scores were positively related to self-report scores of corresponding traits ZSL was a bit overzealous compared to expert gold standards ZSL did a nice job of classifying agreeable responses as agreeable ZSL struggled to classify only relevant responses as agreeable ZSL maintained an inter-rater agreement/reliability approximately 50% to goal","title":"Summary"},{"location":"explorations_code_nbs/exploration_zs_snorkel/","text":"Scaling Expertise Feb 25, 2021 \ud83d\udcd6 ~15 min read Support This Site Strapping domain expertise to a rocket? A potential employee (i.e., candidate) applies for a job. They take assessments\u2013some of which involve responding in her/his own words. How do we evaluate those responses in a reliable , valid , and scaleable manner? Best practices for evaluating open-ended text responses \u2696\ufe0f have been around since 1975 . More recently, these best practices have been combined with the automated essay scoring paradigm \u2013essentially predicting ground truth gold labels of SMEs using natural language processing \u2013 Even with this exciting advancement, having experts go row-by-row evaluating each-and-every-response on a numeric scale is a bottleneck with many limitations \ud83e\udd74 Let's use snorkel.ai a Python package for weak/distant supervision that combines expert precision with state-of-the-art scalability (i.e., coverage ) to label/rate our text responses in terms of a psychological construct; specifically, the Big 5 personality trait of extraversion. Even better, lets create Python labeling functions ( LFs ) out of zero-shot learning ( ZSL ) as a high-coverage heuristic. Summary TLDR: Snorkel is a fitting framework that promotes SMEs ability to impart their wisdom to scale . Specifically, we Programmed functions in Python that mapped onto our SME ground truth gold labels Zero-shot predictions for the 35 factors/facets of the Big 5 personality taxonomy TextBlob sentiment Pattern-based heuristics (i.e., keywords) Created a generative model based on accuracies and correlations of our labeling functions Programmatically labeled all of our unlabeled responses Trained a machine learning model on all (previously unlabeled) data Strategy works with guidelines and ethical considerations for assessment center operations Background on Snorkel There are quite a few resources on Snorkel; such as, this one and this one . Essentially, the tried and true high-precision, low-coverage approach of having SMEs read through and evaluate each response is a bottleneck because: Experts are expensive and can only label so many responses (i.e., low coverage) \ud83d\udcb2 State-of-the-art models require Big Data (i.e., high coverage) \ud83d\udcb2\ud83d\udcb2\ud83d\udcb2 Class definitions/granularity change requiring re-labeling \ud83d\udcb2\ud83e\udd74 Changes in tech such as APIs lose the text/label relationships \ud83d\udcb2\ud83d\ude43 Test security involves multiple/parallel measures that require more labels \ud83d\udcb2\ud83d\udd10 \ud83d\udcf8 Instead of capturing a fleeting snapshot of expertise the idea behind Snorkel is that we can bring all sources of signal to bear including SMEs , to programmatically label limitless text. \u2696\ufe0f The hook is that we incorporate a small subset of expertly rated ground truth gold labels to promote the legal defensibility of our approach. \ud83e\ude99 In this way, we label the population of responses (i.e., coverage) and demonstrate precision with respect to our sample of SME gold. Dataset Let's use the SIOP 2019 ML competition data\u2013focusing on the scenario-based prompt that was written to promote variability in terms of extraversion. Extraversion Prompt \"You and a colleague have had a long day at work and you just find out you have been invited to a networking meeting with one of your largest clients. Your colleague is leaning towards not going and if they don't go you won\u2019t know anyone there. What would you do and why?\" Examples of Gold Label Ground Truth Extraverted Responses \ud83e\ude99 I would go and enjoy myself and network with the client. I have no issue with meeting new people or being in unfamiliar environments. My personality is naturally open and engaging. I would go to the meeting. The purpose is to meet new people and I am up for the task. I consider myself social and would have no problem adjusting. Examples of Gold Label Ground Truth Not Extraverted Responses \ud83e\ude99 I would not go because I am very introverted. It would be awkward and not fun if I did not know anyone else there. Even though it could be beneficial to my career, I would be too anxious to go. I would go home after work. As an introvert, it takes a lot of energy for me to be social and engaged in networking settings, so I would very likely feel uncomfortable and awkward. I would much rather relax at home with my wife and puppy, eat a nice dinner with them, and spend the night watching TV. Setting Up The Dataset Our end goal is to train a machine learning text classifier that can evaluate responses as extraverted or not extraverted (1 for extraverted; 0 for not extraverted). We have a total of 1688 responses. A subject matter expert (me) provided gold label ground truth for 350 responses (about 20%); 120 went into our training split; 115 for our development set; and 115 for test set for a 1:1:1 ratio. We don't typically put gold labels in the training split, but I set it up this way to potentially build baseline models and for diagnostic purposes. Please note in our training split we have the remaining 1338 unlabeled responses . Warning I'm using a very small, open-source dataset to show a minimimally viable walk-through (MVP). The power of this approach is when we have lots of unlabeled data. Still I'm not labeling 1688 responses! Snorkel Flow Machine Teaching The first step (1) is writing labeling functions ( LFs ) in Python that express expertise in terms of evaluating extraversion. Next (2) Snorkel automatically learns a generative model based on the accuracies and correlations of the LFs . Using this generative model, programmatic/soft labels are created for our population of responses. Machine Learning Finally (3) we predict these programmatic/soft labels using a supervised ML model . (1) Signals Used To Program Expertise External models out-of-the-box : Let's use zero-shot learning to build heuristics; that is, classify responses in terms of not just extraversion but all 35 factors/facets of the Big 5 personality taxonomy. ZSL is perfect for providing weak/distant supervision (i.e., coverage). It is a bit noisy\u2013because we didn't explicitly train a model to learn the 35 factors/facets\u2013nevertheless, these weak classifers do quite well in predicting our expertly labeled \ud83e\ude99 extraversion. They're not perfect, but they provide tremendous coverage of all our responses. I did an entire post on zero-shot worth checking out. Journal Article I used the factors/facets found in the APPENDIX of this journal article . Zillig, L. M. P., Hemenover, S. H., & Dienstbier, R. A. (2002). What do we assess when we assess a Big 5 trait? A content analysis of the affective, behavioral, and cognitive processes represented in Big 5 personality inventories. Personality and Social Psychology Bulletin , 28(6), 847-858. To build LFs from zero-shot predictions, I adapted the Snorkel tutorial on crowdsourcing . More Details on Zero-Shot Learning Traditionally, zero-shot learning ( ZSL ) most often referred to a fairly specific type of task: learn a classifier on one set of labels and then evaluate on a different set of labels that the classifier has never seen before. The approach, proposed by Yin et al. (2019) , uses a pre-trained MNLI sequence-pair classifier as an out-of-the-box zero-shot text classifier that actually works pretty well. The idea is to take the sequence we're interested in labeling as the \"premise\" and to turn each candidate label into a \"hypothesis.\" If the NLI model predicts that the premise \"entails\" the hypothesis, we take the label to be true.. Code Example Zero-Shot ! pip install git + https : // github . com / huggingface / transformers . git from transformers import pipeline classifier = pipeline ( \"zero-shot-classification\" ) sequence = ( 'I would go! I would be excited about going. Networking could advance my career. ' 'Networking could bring our company more work.' ) candidate_labels = [ 'agreeableness' , 'conscientiousness' , 'extraversion' , 'neuroticism' , 'openness' ] hypothesis_template = 'This response is characterized by {} .' classifier ( sequence , candidate_labels , multi_class = True , hypothesis_template = hypothesis_template ) Code To Build LFs from Zero-Shot # To create LFs from zero-shot I used the example in the snorkel-tutorial on crowdsourcing # https://github.com/snorkel-team/snorkel-tutorials/tree/master/crowdsourcing labels_by_zs = zs_labels . groupby ( \"candidate_label_id\" ) zs_dicts = {} for zs_id in labels_by_zs . groups : zs_df = labels_by_zs . get_group ( zs_id )[[ \"label\" ]] zs_dicts [ zs_id ] = dict ( zip ( zs_df . index , zs_df . label )) ABSTAIN = - 1 def zs_lf ( x , zs_dict ): return zs_dict . get ( x . response_id , ABSTAIN ) def make_zs_lf ( zs_id ): zs_dict = zs_dicts [ zs_id ] name = f \"lf_ { zs_id } \" return LabelingFunction ( name , f = zs_lf , resources = { \"zs_dict\" : zs_dict }) zs_lfs = [ make_zs_lf ( zs_id ) for zs_id in zs_dicts ] More external models : Positive emotion is a facet of extraversion. Let's use an out-of-the-box model TextBlob to provide signal in terms of positive sentiment I used the example code from the Snorkel documentation . Code TextBlog Labeling Functions from snorkel.preprocess import preprocessor from textblob import TextBlob ABSTAIN = - 1 @preprocessor ( memoize = True ) def textblob_sentiment ( x ): scores = TextBlob ( x . text ) x . polarity = scores . sentiment . polarity x . subjectivity = scores . sentiment . subjectivity return x @labeling_function ( pre = [ textblob_sentiment ]) def polarity_positive ( x ): return 1 if x . polarity > 0.3 else - 1 @labeling_function ( pre = [ textblob_sentiment ]) def polarity_negative ( x ): return 0 if x . polarity < - 0.25 else - 1 @labeling_function ( pre = [ textblob_sentiment ]) def polarity_negative_2 ( x ): return 0 if x . polarity <= 0.3 else - 1 @labeling_function ( pre = [ textblob_sentiment ]) def textblob_subjectivity ( x ): return 1 if x . subjectivity >= 0.5 else ABSTAIN Pattern-based heuristics: I picked up on keywords that reflect extraverted/introverted behaviors Extraverted: extraverted, adventure, exciting, !, extroverted, butterfly, outgoing, upbeat introverted: introverted, awkward, uncomfortable, quiet, intimidating, shy I used the example code from the Snorkel documentation . Code Keyword Labeling Functions def keyword_lookup ( x , keywords , label ): if any ( word in x . text . lower () for word in keywords ): return label return ABSTAIN def make_positive_keyword_lf ( keywords , label = 1 ): return LabelingFunction ( name = f \"keyword_ { keywords [ 0 ] } \" , f = keyword_lookup , resources = dict ( keywords = keywords , label = label ), ) def make_negative_keyword_lf ( keywords , label = 0 ): return LabelingFunction ( name = f \"keyword_ { keywords [ 0 ] } \" , f = keyword_lookup , resources = dict ( keywords = keywords , label = label ), ) keyword_positive = make_positive_keyword_lf ( keywords = [ \"extraverted\" , \"adventure\" , \"exciting\" , \"!\" , \"extroverted\" , \"butterfly\" , \"outgoing\" , \"upbeat\" ] ) keyword_negative = make_negative_keyword_lf ( keywords = [ \"introverted\" , \"awkward\" , \"anxious\" , \"uncomfortable\" , \"quiet\" , \"loner\" , \"intimidating\" , \"disorder\" , \"stressful\" , \"miserable\" , \"shy\" , \"dread\" , \"beg\" , ] ) There are additional ways to express expertise (i.e., build LFs ) check out this link and below. Distant supervision : According to Ratner et al., \"Distant supervision generates training labels by heuristically aligning data points with an external knowledge base, and is one of the most popular forms of weak supervision.\" Labeling-function generators : Again from Ratner et al., we can build labeling functions from crowdsourced labelers such as from Mturk. Note these are not used as gold labels rather for high coverage signal. spaCy syntactics : More advanced NLP such as parts-of-speech (POS) and named entities (NER) can be used to capture nuanced patterns of behavior that represent the psychological constructs of interest. Metrics The power of Snorkel is our LFs , for the same response, will conflict. For example, zero-shot prediction of warmth could predict a 0 (not extraverted) and gregariousness a 1 (extraverted). That's OK we can denoise the conflict \ud83e\udd1d Here are the metrics for when we analyze how our LFs did on the development set, N = 115. Emp. Accuracy : Accuracy of LF predictions. For example, our keywords that represented an introverted response (e.g., shy or awkward ) were 83% accurate. Coverage : % of responses with at least one LF vote, extraverted (1) or not (0). We want coverage . Our keywords that represented an introverted response only had 21% coverage (21/115); whereas, our zero-shot prediction of extraversion has 100% coverage. Polarity : Values the LF returns (1 = extraverted; 0 = not extraverted/introverted). Overlaps & Conflicts : Metric the generative model uses to estimate the accuracy for each LF . If we look at the far right column Emp. Acc. our individuals LFs are pretty accurate. Labeling Function ( LF ) Polarity Coverage Overlaps Conflicts Correct Incorrect Emp. Acc. TextBlog Sentiment Polarity Positive [1] 0.17 0.17 0.16 16 3 0.84 Keywords Introverted [0] 0.21 0.21 0.2 20 4 0.83 Zero-Shot Extraversion [0, 1] 1 1 0.93 89 26 0.77 Zero-Shot Positive Emotions [0, 1] 1 1 0.93 89 26 0.77 Zero-Shot Openness [0, 1] 1 1 0.93 89 26 0.77 Zero-Shot Gregariousness [0, 1] 1 1 0.93 89 26 0.77 Zero-Shot Assertiveness [0, 1] 1 1 0.93 87 28 0.76 Zero-Shot Warmth [0, 1] 1 1 0.93 87 28 0.76 Zero-Shot Excitement Seeking [0, 1] 1 1 0.93 87 28 0.76 Zero-Shot Activity [0, 1] 1 1 0.93 87 28 0.76 TextBlog Sentiment Polarity Negative [0] 0.1 0.1 0.1 9 3 0.75 Zero-Shot Achievement [0, 1] 1 1 0.93 84 31 0.73 Zero-Shot Competence [0, 1] 1 1 0.93 79 36 0.69 Zero-Shot Altruism [0, 1] 1 1 0.93 78 37 0.68 Zero-Shot Trust [0, 1] 1 1 0.93 77 38 0.67 Zero-Shot Agreeableness [0, 1] 1 1 0.93 77 38 0.67 Zero-Shot Actions [0, 1] 1 1 0.93 75 40 0.65 Zero-Shot Aesthetics [0, 1] 1 1 0.93 74 41 0.64 Zero-Shot Ideas [0, 1] 1 1 0.93 74 41 0.64 Zero-Shot Tender Mindedness [0, 1] 1 1 0.93 73 42 0.63 Zero-Shot Impulsiveness [0, 1] 1 1 0.93 72 43 0.63 Keywords Extraverted [1] 0.07 0.07 0.07 5 3 0.62 Zero-Shot Straightforwardness [0, 1] 1 1 0.93 70 45 0.61 TextBlog Polarity Negative_2 [0] 0.83 0.83 0.77 55 41 0.57 Zero-Shot Values [0, 1] 1 1 0.93 63 52 0.55 Zero-Shot Fantasy [0, 1] 1 1 0.93 62 53 0.54 Zero-Shot Conscientiousness [0, 1] 1 1 0.93 61 54 0.53 Zero-Shot Dutifulness [0, 1] 1 1 0.93 60 55 0.52 Textblob Subjectivity [1] 0.5 0.5 0.5 30 28 0.52 (2) Generative Model Next, we take our noisy and conflicting labeling functions and use the Snorkel LabelModel to denoise and combine them using their accuracies and correlations . More accurate LFs are weighted accordingly. To check the quality of our generative model, we score it using our development set. We end up getting accuracy = .77 which is pretty solid considering I plugged-and-played example code from the Snorkel documentation in addition to the zero-shot predictions. \ud83e\ude99 We labeled the population of responses and provided evidence it was precise with respect to our sample of SME ground truth gold labels. The result of this step is the generative model creates labels for all 1338 of our unlabeled responses \ud83d\udc4c Code PandasLFApplier LabelModel from snorkel.analysis import metric_score from snorkel.labeling import PandasLFApplier from snorkel.labeling.model import LabelModel # For this step, I followed the code in the Snorkel tutorial on crowdsourcing # https://github.com/snorkel-team/snorkel-tutorials/tree/master/crowdsourcing # Apply LFs to dev and train applier = PandasLFApplier ( all_lfs ) L_train = applier . apply ( df_train ) L_dev = applier . apply ( df_dev ) # Train LabelModel label_model = LabelModel ( cardinality = 2 , verbose = True ) label_model . fit ( L_train , n_epochs = 100 , seed = 123 , log_freq = 20 , l2 = 0.1 , lr = 0.01 ) # Score LabelModel on our dev set preds_dev = label_model . predict ( L_dev ) acc = metric_score ( df_dev . gold . values , preds_dev , probs = None , metric = \"accuracy\" ) print ( f \"LabelModel Accuracy: { acc : .3f } \" ) # Output # LabelModel Accuracy: 0.765 # Generate labels for our 1338 unlabeled responses preds_train = label_model . predict ( L_train ) (3) Predict Labels Using ML Now we have our 1338 programmatic/soft labels, at this point we disregard the LFs and build a machine-learning model simply using 2 things: text responses and a column of ones and zeroes, extraverted response or not, respectively. Consistent with the Snorkel tutorial, I used BERT, a pre-trained language model, and trained a logistic regression model using the BERT features on our 1338 labels. For a stronger approach that can harness Big Data check out this article . The accuracy of the trained model was .72 a little bit of shrinkage (~6.5%), but keep in mind we have very small data. I'm not going to beat myself up. There are articles in top assessment journals that don't have this level of accuracy. Code Predict Soft Labels using Supervised ML from snorkel.analysis import metric_score from snorkel.labeling import PandasLFApplier from snorkel.labeling.model import LabelModel # For this step, I followed the code in the Snorkel tutorial on crowdsourcing # https://github.com/snorkel-team/snorkel-tutorials/tree/master/crowdsourcing import numpy as np import torch from pytorch_transformers import BertModel , BertTokenizer model = BertModel . from_pretrained ( \"bert-base-uncased\" ) tokenizer = BertTokenizer . from_pretrained ( \"bert-base-uncased\" ) def encode_text ( text ): input_ids = torch . tensor ([ tokenizer . encode ( text )]) return model ( input_ids )[ 0 ] . mean ( 1 )[ 0 ] . detach () . numpy () X_train = np . array ( list ( df_train . tweet_text . apply ( encode_text ) . values )) X_test = np . array ( list ( df_test . tweet_text . apply ( encode_text ) . values )) from sklearn.linear_model import LogisticRegression sklearn_model = LogisticRegression ( solver = \"liblinear\" ) sklearn_model . fit ( X_train , preds_train ) print ( f \"Accuracy of trained model: { sklearn_model . score ( X_test , Y_test ) } \" ) # Output # Accuracy of trained model: 0.715 Conclusion In 1975, Bill Gates and Paul Allen started Microsoft. The Suez Canal reopened and best practices for evaluating open-ended text responses in the talent space were assembled \ud83c\udf7e The spirit of this post is to channel those seemingly fleeting snapshots of subject matter expertise (i.e., precision) into Python labeling functions ( LFs ) to be applied to all of our data (i.e., coverage) and on demand (Think: AWS) to evaluate fresh\u2013yet to be labeled data. The framework of weak/distant supervision (e.g., Snorkel) is especially fitting because it incorporates expertly rated ground truth gold labels to help buoy the legal defensibility of this strategy. I spent 90 minutes providing gold labels for 350 responses in terms of extraversion and ended up with an end model trained on 1338 responses with an accuracy of .72. That's a solid start using small, open-source data. Derek L Mracek, PhD Support This Site Summary TLDR: Snorkel is a fitting framework that promotes SMEs ability to impart their wisdom to scale . Specifically, we Programmed functions in Python that mapped onto our SME ground truth gold labels Zero-shot predictions for the 35 factors/facets of the Big 5 personality taxonomy TextBlob sentiment Pattern-based heuristics (i.e., keywords) Created a generative model based on accuracies and correlations of our labeling functions Programmatically labeled all of our unlabeled responses Trained a machine learning model on all (previously unlabeled) data Strategy works with guidelines and ethical considerations for assessment center operations","title":"Scaling Expertise"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#scaling-expertise","text":"Feb 25, 2021 \ud83d\udcd6 ~15 min read Support This Site","title":"Scaling Expertise"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#strapping-domain-expertise-to-a-rocket","text":"A potential employee (i.e., candidate) applies for a job. They take assessments\u2013some of which involve responding in her/his own words. How do we evaluate those responses in a reliable , valid , and scaleable manner? Best practices for evaluating open-ended text responses \u2696\ufe0f have been around since 1975 . More recently, these best practices have been combined with the automated essay scoring paradigm \u2013essentially predicting ground truth gold labels of SMEs using natural language processing \u2013 Even with this exciting advancement, having experts go row-by-row evaluating each-and-every-response on a numeric scale is a bottleneck with many limitations \ud83e\udd74 Let's use snorkel.ai a Python package for weak/distant supervision that combines expert precision with state-of-the-art scalability (i.e., coverage ) to label/rate our text responses in terms of a psychological construct; specifically, the Big 5 personality trait of extraversion. Even better, lets create Python labeling functions ( LFs ) out of zero-shot learning ( ZSL ) as a high-coverage heuristic.","title":"Strapping domain expertise to a rocket?"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#summary","text":"TLDR: Snorkel is a fitting framework that promotes SMEs ability to impart their wisdom to scale . Specifically, we Programmed functions in Python that mapped onto our SME ground truth gold labels Zero-shot predictions for the 35 factors/facets of the Big 5 personality taxonomy TextBlob sentiment Pattern-based heuristics (i.e., keywords) Created a generative model based on accuracies and correlations of our labeling functions Programmatically labeled all of our unlabeled responses Trained a machine learning model on all (previously unlabeled) data Strategy works with guidelines and ethical considerations for assessment center operations","title":"Summary"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#background-on-snorkel","text":"There are quite a few resources on Snorkel; such as, this one and this one . Essentially, the tried and true high-precision, low-coverage approach of having SMEs read through and evaluate each response is a bottleneck because: Experts are expensive and can only label so many responses (i.e., low coverage) \ud83d\udcb2 State-of-the-art models require Big Data (i.e., high coverage) \ud83d\udcb2\ud83d\udcb2\ud83d\udcb2 Class definitions/granularity change requiring re-labeling \ud83d\udcb2\ud83e\udd74 Changes in tech such as APIs lose the text/label relationships \ud83d\udcb2\ud83d\ude43 Test security involves multiple/parallel measures that require more labels \ud83d\udcb2\ud83d\udd10 \ud83d\udcf8 Instead of capturing a fleeting snapshot of expertise the idea behind Snorkel is that we can bring all sources of signal to bear including SMEs , to programmatically label limitless text. \u2696\ufe0f The hook is that we incorporate a small subset of expertly rated ground truth gold labels to promote the legal defensibility of our approach. \ud83e\ude99 In this way, we label the population of responses (i.e., coverage) and demonstrate precision with respect to our sample of SME gold.","title":"Background on Snorkel"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#dataset","text":"Let's use the SIOP 2019 ML competition data\u2013focusing on the scenario-based prompt that was written to promote variability in terms of extraversion. Extraversion Prompt \"You and a colleague have had a long day at work and you just find out you have been invited to a networking meeting with one of your largest clients. Your colleague is leaning towards not going and if they don't go you won\u2019t know anyone there. What would you do and why?\" Examples of Gold Label Ground Truth Extraverted Responses \ud83e\ude99 I would go and enjoy myself and network with the client. I have no issue with meeting new people or being in unfamiliar environments. My personality is naturally open and engaging. I would go to the meeting. The purpose is to meet new people and I am up for the task. I consider myself social and would have no problem adjusting. Examples of Gold Label Ground Truth Not Extraverted Responses \ud83e\ude99 I would not go because I am very introverted. It would be awkward and not fun if I did not know anyone else there. Even though it could be beneficial to my career, I would be too anxious to go. I would go home after work. As an introvert, it takes a lot of energy for me to be social and engaged in networking settings, so I would very likely feel uncomfortable and awkward. I would much rather relax at home with my wife and puppy, eat a nice dinner with them, and spend the night watching TV.","title":"Dataset"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#setting-up-the-dataset","text":"Our end goal is to train a machine learning text classifier that can evaluate responses as extraverted or not extraverted (1 for extraverted; 0 for not extraverted). We have a total of 1688 responses. A subject matter expert (me) provided gold label ground truth for 350 responses (about 20%); 120 went into our training split; 115 for our development set; and 115 for test set for a 1:1:1 ratio. We don't typically put gold labels in the training split, but I set it up this way to potentially build baseline models and for diagnostic purposes. Please note in our training split we have the remaining 1338 unlabeled responses . Warning I'm using a very small, open-source dataset to show a minimimally viable walk-through (MVP). The power of this approach is when we have lots of unlabeled data. Still I'm not labeling 1688 responses!","title":"Setting Up The Dataset"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#snorkel-flow","text":"","title":"Snorkel Flow"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#machine-teaching","text":"The first step (1) is writing labeling functions ( LFs ) in Python that express expertise in terms of evaluating extraversion. Next (2) Snorkel automatically learns a generative model based on the accuracies and correlations of the LFs . Using this generative model, programmatic/soft labels are created for our population of responses.","title":"Machine Teaching"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#machine-learning","text":"Finally (3) we predict these programmatic/soft labels using a supervised ML model .","title":"Machine Learning"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#1-signals-used-to-program-expertise","text":"External models out-of-the-box : Let's use zero-shot learning to build heuristics; that is, classify responses in terms of not just extraversion but all 35 factors/facets of the Big 5 personality taxonomy. ZSL is perfect for providing weak/distant supervision (i.e., coverage). It is a bit noisy\u2013because we didn't explicitly train a model to learn the 35 factors/facets\u2013nevertheless, these weak classifers do quite well in predicting our expertly labeled \ud83e\ude99 extraversion. They're not perfect, but they provide tremendous coverage of all our responses. I did an entire post on zero-shot worth checking out. Journal Article I used the factors/facets found in the APPENDIX of this journal article . Zillig, L. M. P., Hemenover, S. H., & Dienstbier, R. A. (2002). What do we assess when we assess a Big 5 trait? A content analysis of the affective, behavioral, and cognitive processes represented in Big 5 personality inventories. Personality and Social Psychology Bulletin , 28(6), 847-858. To build LFs from zero-shot predictions, I adapted the Snorkel tutorial on crowdsourcing . More Details on Zero-Shot Learning Traditionally, zero-shot learning ( ZSL ) most often referred to a fairly specific type of task: learn a classifier on one set of labels and then evaluate on a different set of labels that the classifier has never seen before. The approach, proposed by Yin et al. (2019) , uses a pre-trained MNLI sequence-pair classifier as an out-of-the-box zero-shot text classifier that actually works pretty well. The idea is to take the sequence we're interested in labeling as the \"premise\" and to turn each candidate label into a \"hypothesis.\" If the NLI model predicts that the premise \"entails\" the hypothesis, we take the label to be true.. Code Example Zero-Shot ! pip install git + https : // github . com / huggingface / transformers . git from transformers import pipeline classifier = pipeline ( \"zero-shot-classification\" ) sequence = ( 'I would go! I would be excited about going. Networking could advance my career. ' 'Networking could bring our company more work.' ) candidate_labels = [ 'agreeableness' , 'conscientiousness' , 'extraversion' , 'neuroticism' , 'openness' ] hypothesis_template = 'This response is characterized by {} .' classifier ( sequence , candidate_labels , multi_class = True , hypothesis_template = hypothesis_template ) Code To Build LFs from Zero-Shot # To create LFs from zero-shot I used the example in the snorkel-tutorial on crowdsourcing # https://github.com/snorkel-team/snorkel-tutorials/tree/master/crowdsourcing labels_by_zs = zs_labels . groupby ( \"candidate_label_id\" ) zs_dicts = {} for zs_id in labels_by_zs . groups : zs_df = labels_by_zs . get_group ( zs_id )[[ \"label\" ]] zs_dicts [ zs_id ] = dict ( zip ( zs_df . index , zs_df . label )) ABSTAIN = - 1 def zs_lf ( x , zs_dict ): return zs_dict . get ( x . response_id , ABSTAIN ) def make_zs_lf ( zs_id ): zs_dict = zs_dicts [ zs_id ] name = f \"lf_ { zs_id } \" return LabelingFunction ( name , f = zs_lf , resources = { \"zs_dict\" : zs_dict }) zs_lfs = [ make_zs_lf ( zs_id ) for zs_id in zs_dicts ] More external models : Positive emotion is a facet of extraversion. Let's use an out-of-the-box model TextBlob to provide signal in terms of positive sentiment I used the example code from the Snorkel documentation . Code TextBlog Labeling Functions from snorkel.preprocess import preprocessor from textblob import TextBlob ABSTAIN = - 1 @preprocessor ( memoize = True ) def textblob_sentiment ( x ): scores = TextBlob ( x . text ) x . polarity = scores . sentiment . polarity x . subjectivity = scores . sentiment . subjectivity return x @labeling_function ( pre = [ textblob_sentiment ]) def polarity_positive ( x ): return 1 if x . polarity > 0.3 else - 1 @labeling_function ( pre = [ textblob_sentiment ]) def polarity_negative ( x ): return 0 if x . polarity < - 0.25 else - 1 @labeling_function ( pre = [ textblob_sentiment ]) def polarity_negative_2 ( x ): return 0 if x . polarity <= 0.3 else - 1 @labeling_function ( pre = [ textblob_sentiment ]) def textblob_subjectivity ( x ): return 1 if x . subjectivity >= 0.5 else ABSTAIN Pattern-based heuristics: I picked up on keywords that reflect extraverted/introverted behaviors Extraverted: extraverted, adventure, exciting, !, extroverted, butterfly, outgoing, upbeat introverted: introverted, awkward, uncomfortable, quiet, intimidating, shy I used the example code from the Snorkel documentation . Code Keyword Labeling Functions def keyword_lookup ( x , keywords , label ): if any ( word in x . text . lower () for word in keywords ): return label return ABSTAIN def make_positive_keyword_lf ( keywords , label = 1 ): return LabelingFunction ( name = f \"keyword_ { keywords [ 0 ] } \" , f = keyword_lookup , resources = dict ( keywords = keywords , label = label ), ) def make_negative_keyword_lf ( keywords , label = 0 ): return LabelingFunction ( name = f \"keyword_ { keywords [ 0 ] } \" , f = keyword_lookup , resources = dict ( keywords = keywords , label = label ), ) keyword_positive = make_positive_keyword_lf ( keywords = [ \"extraverted\" , \"adventure\" , \"exciting\" , \"!\" , \"extroverted\" , \"butterfly\" , \"outgoing\" , \"upbeat\" ] ) keyword_negative = make_negative_keyword_lf ( keywords = [ \"introverted\" , \"awkward\" , \"anxious\" , \"uncomfortable\" , \"quiet\" , \"loner\" , \"intimidating\" , \"disorder\" , \"stressful\" , \"miserable\" , \"shy\" , \"dread\" , \"beg\" , ] ) There are additional ways to express expertise (i.e., build LFs ) check out this link and below. Distant supervision : According to Ratner et al., \"Distant supervision generates training labels by heuristically aligning data points with an external knowledge base, and is one of the most popular forms of weak supervision.\" Labeling-function generators : Again from Ratner et al., we can build labeling functions from crowdsourced labelers such as from Mturk. Note these are not used as gold labels rather for high coverage signal. spaCy syntactics : More advanced NLP such as parts-of-speech (POS) and named entities (NER) can be used to capture nuanced patterns of behavior that represent the psychological constructs of interest.","title":"(1) Signals Used To Program Expertise"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#metrics","text":"The power of Snorkel is our LFs , for the same response, will conflict. For example, zero-shot prediction of warmth could predict a 0 (not extraverted) and gregariousness a 1 (extraverted). That's OK we can denoise the conflict \ud83e\udd1d Here are the metrics for when we analyze how our LFs did on the development set, N = 115. Emp. Accuracy : Accuracy of LF predictions. For example, our keywords that represented an introverted response (e.g., shy or awkward ) were 83% accurate. Coverage : % of responses with at least one LF vote, extraverted (1) or not (0). We want coverage . Our keywords that represented an introverted response only had 21% coverage (21/115); whereas, our zero-shot prediction of extraversion has 100% coverage. Polarity : Values the LF returns (1 = extraverted; 0 = not extraverted/introverted). Overlaps & Conflicts : Metric the generative model uses to estimate the accuracy for each LF . If we look at the far right column Emp. Acc. our individuals LFs are pretty accurate. Labeling Function ( LF ) Polarity Coverage Overlaps Conflicts Correct Incorrect Emp. Acc. TextBlog Sentiment Polarity Positive [1] 0.17 0.17 0.16 16 3 0.84 Keywords Introverted [0] 0.21 0.21 0.2 20 4 0.83 Zero-Shot Extraversion [0, 1] 1 1 0.93 89 26 0.77 Zero-Shot Positive Emotions [0, 1] 1 1 0.93 89 26 0.77 Zero-Shot Openness [0, 1] 1 1 0.93 89 26 0.77 Zero-Shot Gregariousness [0, 1] 1 1 0.93 89 26 0.77 Zero-Shot Assertiveness [0, 1] 1 1 0.93 87 28 0.76 Zero-Shot Warmth [0, 1] 1 1 0.93 87 28 0.76 Zero-Shot Excitement Seeking [0, 1] 1 1 0.93 87 28 0.76 Zero-Shot Activity [0, 1] 1 1 0.93 87 28 0.76 TextBlog Sentiment Polarity Negative [0] 0.1 0.1 0.1 9 3 0.75 Zero-Shot Achievement [0, 1] 1 1 0.93 84 31 0.73 Zero-Shot Competence [0, 1] 1 1 0.93 79 36 0.69 Zero-Shot Altruism [0, 1] 1 1 0.93 78 37 0.68 Zero-Shot Trust [0, 1] 1 1 0.93 77 38 0.67 Zero-Shot Agreeableness [0, 1] 1 1 0.93 77 38 0.67 Zero-Shot Actions [0, 1] 1 1 0.93 75 40 0.65 Zero-Shot Aesthetics [0, 1] 1 1 0.93 74 41 0.64 Zero-Shot Ideas [0, 1] 1 1 0.93 74 41 0.64 Zero-Shot Tender Mindedness [0, 1] 1 1 0.93 73 42 0.63 Zero-Shot Impulsiveness [0, 1] 1 1 0.93 72 43 0.63 Keywords Extraverted [1] 0.07 0.07 0.07 5 3 0.62 Zero-Shot Straightforwardness [0, 1] 1 1 0.93 70 45 0.61 TextBlog Polarity Negative_2 [0] 0.83 0.83 0.77 55 41 0.57 Zero-Shot Values [0, 1] 1 1 0.93 63 52 0.55 Zero-Shot Fantasy [0, 1] 1 1 0.93 62 53 0.54 Zero-Shot Conscientiousness [0, 1] 1 1 0.93 61 54 0.53 Zero-Shot Dutifulness [0, 1] 1 1 0.93 60 55 0.52 Textblob Subjectivity [1] 0.5 0.5 0.5 30 28 0.52","title":"Metrics"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#2-generative-model","text":"Next, we take our noisy and conflicting labeling functions and use the Snorkel LabelModel to denoise and combine them using their accuracies and correlations . More accurate LFs are weighted accordingly. To check the quality of our generative model, we score it using our development set. We end up getting accuracy = .77 which is pretty solid considering I plugged-and-played example code from the Snorkel documentation in addition to the zero-shot predictions. \ud83e\ude99 We labeled the population of responses and provided evidence it was precise with respect to our sample of SME ground truth gold labels. The result of this step is the generative model creates labels for all 1338 of our unlabeled responses \ud83d\udc4c Code PandasLFApplier LabelModel from snorkel.analysis import metric_score from snorkel.labeling import PandasLFApplier from snorkel.labeling.model import LabelModel # For this step, I followed the code in the Snorkel tutorial on crowdsourcing # https://github.com/snorkel-team/snorkel-tutorials/tree/master/crowdsourcing # Apply LFs to dev and train applier = PandasLFApplier ( all_lfs ) L_train = applier . apply ( df_train ) L_dev = applier . apply ( df_dev ) # Train LabelModel label_model = LabelModel ( cardinality = 2 , verbose = True ) label_model . fit ( L_train , n_epochs = 100 , seed = 123 , log_freq = 20 , l2 = 0.1 , lr = 0.01 ) # Score LabelModel on our dev set preds_dev = label_model . predict ( L_dev ) acc = metric_score ( df_dev . gold . values , preds_dev , probs = None , metric = \"accuracy\" ) print ( f \"LabelModel Accuracy: { acc : .3f } \" ) # Output # LabelModel Accuracy: 0.765 # Generate labels for our 1338 unlabeled responses preds_train = label_model . predict ( L_train )","title":"(2) Generative Model"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#3-predict-labels-using-ml","text":"Now we have our 1338 programmatic/soft labels, at this point we disregard the LFs and build a machine-learning model simply using 2 things: text responses and a column of ones and zeroes, extraverted response or not, respectively. Consistent with the Snorkel tutorial, I used BERT, a pre-trained language model, and trained a logistic regression model using the BERT features on our 1338 labels. For a stronger approach that can harness Big Data check out this article . The accuracy of the trained model was .72 a little bit of shrinkage (~6.5%), but keep in mind we have very small data. I'm not going to beat myself up. There are articles in top assessment journals that don't have this level of accuracy. Code Predict Soft Labels using Supervised ML from snorkel.analysis import metric_score from snorkel.labeling import PandasLFApplier from snorkel.labeling.model import LabelModel # For this step, I followed the code in the Snorkel tutorial on crowdsourcing # https://github.com/snorkel-team/snorkel-tutorials/tree/master/crowdsourcing import numpy as np import torch from pytorch_transformers import BertModel , BertTokenizer model = BertModel . from_pretrained ( \"bert-base-uncased\" ) tokenizer = BertTokenizer . from_pretrained ( \"bert-base-uncased\" ) def encode_text ( text ): input_ids = torch . tensor ([ tokenizer . encode ( text )]) return model ( input_ids )[ 0 ] . mean ( 1 )[ 0 ] . detach () . numpy () X_train = np . array ( list ( df_train . tweet_text . apply ( encode_text ) . values )) X_test = np . array ( list ( df_test . tweet_text . apply ( encode_text ) . values )) from sklearn.linear_model import LogisticRegression sklearn_model = LogisticRegression ( solver = \"liblinear\" ) sklearn_model . fit ( X_train , preds_train ) print ( f \"Accuracy of trained model: { sklearn_model . score ( X_test , Y_test ) } \" ) # Output # Accuracy of trained model: 0.715","title":"(3) Predict Labels Using ML"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#conclusion","text":"In 1975, Bill Gates and Paul Allen started Microsoft. The Suez Canal reopened and best practices for evaluating open-ended text responses in the talent space were assembled \ud83c\udf7e The spirit of this post is to channel those seemingly fleeting snapshots of subject matter expertise (i.e., precision) into Python labeling functions ( LFs ) to be applied to all of our data (i.e., coverage) and on demand (Think: AWS) to evaluate fresh\u2013yet to be labeled data. The framework of weak/distant supervision (e.g., Snorkel) is especially fitting because it incorporates expertly rated ground truth gold labels to help buoy the legal defensibility of this strategy. I spent 90 minutes providing gold labels for 350 responses in terms of extraversion and ended up with an end model trained on 1338 responses with an accuracy of .72. That's a solid start using small, open-source data. Derek L Mracek, PhD Support This Site","title":"Conclusion"},{"location":"explorations_code_nbs/exploration_zs_snorkel/#summary_1","text":"TLDR: Snorkel is a fitting framework that promotes SMEs ability to impart their wisdom to scale . Specifically, we Programmed functions in Python that mapped onto our SME ground truth gold labels Zero-shot predictions for the 35 factors/facets of the Big 5 personality taxonomy TextBlob sentiment Pattern-based heuristics (i.e., keywords) Created a generative model based on accuracies and correlations of our labeling functions Programmatically labeled all of our unlabeled responses Trained a machine learning model on all (previously unlabeled) data Strategy works with guidelines and ethical considerations for assessment center operations","title":"Summary"},{"location":"explorations_code_nbs/template_exploration_v1/","text":"Title Work in progress","title":"**Title**"},{"location":"explorations_code_nbs/template_exploration_v1/#title","text":"","title":"Title"},{"location":"explorations_code_nbs/template_exploration_v1/#work-in-progress","text":"","title":"Work in progress"}]}